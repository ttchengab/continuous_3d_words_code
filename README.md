# Learning Continuous 3D Words for Text-to-Image Generation


<a href='https://ttchengab.github.io/continuous_3d_words'><img src='https://img.shields.io/badge/Project-Page-green'></a> 
<a href='https://ttchengab.github.io/continuous_3d_words/c3d_words.pdf'><img src='https://img.shields.io/badge/Paper-blue'></a> 

## Introduction
We present Continuous 3D Words, a way to encode fine-grained attributes like illumination, non-rigid shape changes, and camera parameters as special tokens for text-to-image generation.

Code in `lora_diffusion/` is adapted from the LoRA implementation from cloneofsimo which can be found [here](https://github.com/cloneofsimo/lora). Please comply to their LICENSE accordingly.

## Installation

```
# The model is tested with diffusers 0.16.1
pip install -r requirements.txt

# then you can use the notebook for demo.
```

## Download Pretrained Checkpoints


## Updates
- [Feb 14, 2024] Demos for illumination and non-rigid running is added ðŸ”¥. The training scripts will be added soon ðŸš§.
